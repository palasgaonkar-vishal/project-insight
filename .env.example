# Environment Variables for AI-Powered Delivery Failure Analysis
# Copy this file to .env and fill in your actual values

# LLM Provider Configuration
LLM_PROVIDER=openrouter  # or "openai"

# OpenAI API Configuration (if using OpenAI)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4
OPENAI_TEMPERATURE=0.1

# OpenRouter API Configuration (if using OpenRouter)
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_MODEL=deepseek/deepseek-r1-0528:free
OPENROUTER_TEMPERATURE=0.1

# Database Configuration
DATABASE_PATH=data/delivery_failures.db
VECTOR_DB_PATH=data/vector_db

# RAG Engine Configuration
DEFAULT_CONTEXT_SIZE=10
MAX_CONTEXT_SIZE=20
CONFIDENCE_THRESHOLD=0.5

# Vector Database Configuration
SENTENCE_TRANSFORMER_MODEL=all-MiniLM-L6-v2

# Logging Configuration
LOG_LEVEL=INFO
LOG_FILE=logs/app.log

# Performance Configuration
CHUNK_SIZE=1000
MAX_MEMORY_USAGE=10000  # MB
CACHE_SIZE=1000
